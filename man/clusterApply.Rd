% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SparkSimple.R
\name{clusterApply}
\alias{clusterApply}
\title{Parallelize computations using a Spark cluster}
\usage{
clusterApply(cl, x, fun, ...)
}
\arguments{
\item{cl}{cluster is a Spark connection as returned from
\code{\link[sparkapi]{start_shell}}}

\item{x}{R object that can be coerced to list}

\item{fun}{function to evaluate}
}
\value{
list with \code{fun} evaluated at each element of x
}
\description{
This works by serializing x onto the worker nodes, running the
computation, and finally deserializing the result.
}
\examples{
library(sparkapi)
sc <- start_shell(master = "local")
clusterApply(sc, 1:10, function(x) x + 2)

}
\seealso{
\code{\link[base]{lapply}}, 
     \code{\link[parallel]{clusterApply}} in \code{parallel} package
}

